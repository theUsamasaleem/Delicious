{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KNN.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "class KNearestNeighbor:\n",
        "    def __init__(self, k):\n",
        "        self.k = k\n",
        "        self.eps = 1e-8\n",
        "\n",
        "    def train(self, X, y):\n",
        "        self.X_train = X\n",
        "        self.y_train = y\n",
        "\n",
        "    def predict(self, X_test, num_loops=0):\n",
        "        if num_loops == 0:\n",
        "            distances = self.compute_distance_vectorized(X_test)\n",
        "\n",
        "        elif num_loops == 1:\n",
        "            distances = self.compute_distance_one_loop(X_test)\n",
        "\n",
        "        else:\n",
        "            distances = self.compute_distance_two_loops(X_test)\n",
        "\n",
        "        return self.predict_labels(distances)\n",
        "\n",
        "    def compute_distance_two_loops(self, X_test):\n",
        "        \"\"\"\n",
        "        Inefficient naive implementation, use only\n",
        "        as a way of understanding what kNN is doing\n",
        "        \"\"\"\n",
        "\n",
        "        num_test = X_test.shape[0]\n",
        "        num_train = self.X_train.shape[0]\n",
        "        distances = np.zeros((num_test, num_train))\n",
        "\n",
        "        for i in range(num_test):\n",
        "            for j in range(num_train):\n",
        "                # (Taking sqrt is not necessary: min distance won't change since sqrt is monotone)\n",
        "                distances[i, j] = np.sqrt(\n",
        "                    self.eps + np.sum((X_test[i, :] - self.X_train[j, :]) ** 2)\n",
        "                )\n",
        "\n",
        "        return distances\n",
        "\n",
        "    def compute_distance_one_loop(self, X_test):\n",
        "        \"\"\"\n",
        "        Much better than two-loops but not as fast as fully vectorized version.\n",
        "        Utilize Numpy broadcasting in X_train - X_test[i,:]\n",
        "        \"\"\"\n",
        "        num_test = X_test.shape[0]\n",
        "        num_train = self.X_train.shape[0]\n",
        "        distances = np.zeros((num_test, num_train))\n",
        "\n",
        "        for i in range(num_test):\n",
        "            # (Taking sqrt is not necessary: min distance won't change since sqrt is monotone)\n",
        "            distances[i, :] = np.sqrt(\n",
        "                self.eps + np.sum((self.X_train - X_test[i, :]) ** 2, axis=1)\n",
        "            )\n",
        "\n",
        "        return distances\n",
        "\n",
        "    def compute_distance_vectorized(self, X_test):\n",
        "        \"\"\"\n",
        "        Can be tricky to understand this, we utilize heavy\n",
        "        vecotorization as well as numpy broadcasting.\n",
        "        Idea: if we have two vectors a, b (two examples)\n",
        "        and for vectors we can compute (a-b)^2 = a^2 - 2a (dot) b + b^2\n",
        "        expanding on this and doing so for every vector lends to the \n",
        "        heavy vectorized formula for all examples at the same time.\n",
        "        \"\"\"\n",
        "        X_test_squared = np.sum(X_test ** 2, axis=1, keepdims=True)\n",
        "        X_train_squared = np.sum(self.X_train ** 2, axis=1, keepdims=True)\n",
        "        two_X_test_X_train = np.dot(X_test, self.X_train.T)\n",
        "\n",
        "        # (Taking sqrt is not necessary: min distance won't change since sqrt is monotone)\n",
        "        return np.sqrt(\n",
        "            self.eps + X_test_squared - 2 * two_X_test_X_train + X_train_squared.T\n",
        "        )\n",
        "\n",
        "    def predict_labels(self, distances):\n",
        "        num_test = distances.shape[0]\n",
        "        y_pred = np.zeros(num_test)\n",
        "\n",
        "        for i in range(num_test):\n",
        "            y_indices = np.argsort(distances[i, :])\n",
        "            k_closest_classes = self.y_train[y_indices[: self.k]].astype(int)\n",
        "            y_pred[i] = np.argmax(np.bincount(k_closest_classes))\n",
        "\n",
        "        return y_pred\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    X = np.loadtxt(\"data.txt\", delimiter=\",\")\n",
        "    y = np.loadtxt(\"targets.txt\")\n",
        "\n",
        "    X = np.array([[1, 1], [3, 1], [1, 4], [2, 4], [3, 3], [5, 1]])\n",
        "    y = np.array([0, 0, 0, 1, 1, 1])\n",
        "\n",
        "    KNN = KNearestNeighbor(k=3)\n",
        "    KNN.train(X, y)\n",
        "    y_pred = KNN.predict(X, num_loops=0)\n",
        "    print(f\"Accuracy: {sum(y_pred == y) / y.shape[0]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZCCxkvUlTvEU",
        "outputId": "6e81de2d-1b27-478c-aca0-de5eaeee5141"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8333333333333334\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "4lt-_JOyUXCS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}